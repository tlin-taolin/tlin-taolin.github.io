<!-- <h4><a name="Conference & Journals"></a>Conference & Journal papers</h4> -->
<ol reversed>
  <li>
    <b>RelaySum for Decentralized Deep Learning on Heterogeneous Data.</b><br>              
    Thijs Vogels*, Lie He*, Anastasia Koloskova, <b>Tao Lin</b>, Sai Praneeth Karimireddy, Sebastian U. Stich, Martin Jaggi.<br>
    NeurIPS 2021
    • <a href="https://arxiv.org/abs/2110.04175">paper</a>
    • <a href="https://github.com/epfml/relaysgd">code</a>
    • <a href="https://youtu.be/NyQYP35-9OY">video</a>
    • <a href="https://thijsvogels.nl/relaysgd-slides">slides</a>
    • <a href="#" onclick="showBibTex(this); return false">bibtex</a>
    <code class="bibtex">@inproceedings{vogels-he2021relaysgd,
title     = {RelaySum for Decentralized Deep Learning on Heterogeneous Data},
author    = {Vogels, Thijs and He, Lie and Koloskova, Anastasia and Lin, Tao and Karimireddy, Sai Praneeth and Stich, Sebastian U. and Jaggi, Martin},
journal   = {Advances in Neural Information Processing Systems 34},
year      = {2021},
}</code>
  </li>

  <li>
    <b>An Improved Analysis of Gradient Tracking for Decentralized Machine Learning.</b><br>              
    Anastasia Koloskova, <b>Tao Lin</b>, Sebastian U. Stich.<br>
    NeurIPS 2021
    • <a href="https://arxiv.org/abs/2202.03836">paper</a>
    • <a href="https://openreview.net/forum?id=CmI7NqBR4Ua">openreview</a>
    • <a href="#" onclick="showBibTex(this); return false">bibtex</a>
    <code class="bibtex">@inproceedings{koloskova2021an,
title     = {An Improved Analysis of Gradient Tracking for Decentralized Machine Learning},
author    = {Koloskova, Anastasia and Lin, Tao and Stich, Sebastian U.},
journal   = {Advances in Neural Information Processing Systems 34},
year      = {2021},
}</code>
  </li>

  <li>
      <b>Quasi-Global Momentum: Accelerating Decentralized Deep Learning on Heterogeneous Data.</b><br>
      <b>Tao Lin</b>, Sai Praneeth Karimireddy, Sebastian U. Stich, Martin Jaggi.<br>
      ICML 2021 
      • <a href="https://arxiv.org/abs/2102.04761">paper</a>
      • <a href="https://github.com/epfml/quasi-global-momentum">code</a> 
      • <a href="#" onclick="showBibTex(this); return false">bibtex</a>
      <code class="bibtex">@inproceedings{lin2021quasi,
title     = {Quasi-global momentum: Accelerating decentralized deep learning on heterogeneous data},
author    = {Lin, Tao and Karimireddy, Sai Praneeth and Stich, Sebastian U and Jaggi, Martin},
booktitle = {International Conference on Machine Learning},
year      = {2021}
}</code>             
  </li>

  <li>
      <b>Consensus Control for Decentralized Deep Learning.</b><br>
      Lingjing Kong*, <b>Tao Lin*</b><sup>†</sup>, Anastasia Koloskova, Martin Jaggi, Sebastian U. Stich.<br>
      ICML 2021 
      • <a href="https://arxiv.org/abs/2102.04828">paper</a>
      • <a href="#" onclick="showBibTex(this); return false">bibtex</a>
      <code class="bibtex">@inproceedings{kong2021consensus,
title     = {Consensus Control for Decentralized Deep Learning},
author    = {Kong, Lingjing and Lin, Tao and Koloskova, Anastasia and Jaggi, Martin and Stich, Sebastian U},
booktitle = {International Conference on Machine Learning},
year      = {2021}
}</code> 
  </li>
  
  <li>
      <b>Ensemble Distillation for Robust Model Fusion in Federated Learning.</b><br>
      <b>Tao Lin*</b>, Lingjing Kong*, Sebastian U. Stich, Martin Jaggi.<br>
      NeurIPS 2020
      • <a href="https://arxiv.org/abs/2006.07242">paper</a>
      • <a href="https://github.com/epfml/federated-learning-public-code">code</a>
      • <a href="#" onclick="showBibTex(this); return false">bibtex</a>
      <code class="bibtex">@inproceedings{lin2020ensemble,
title     = {Ensemble distillation for robust model fusion in federated learning},
author    = {Lin, Tao and Kong, Lingjing and Stich, Sebastian U and Jaggi, Martin},
booktitle = {Advances in Neural Information Processing Systems},
year      = {2020}
}</code>
  </li>

  <li>
    <b>On the Loss Landscape of Adversarial Training: Identifying Challenges and How to Overcome Them.</b><br>
    Chen Liu, Mathieu Salzmann, <b>Tao Lin</b>, Ryota Tomioka, Sabine Süsstrunk.<br>
    NeurIPS 2020
    • <a href="https://arxiv.org/abs/2006.08403">paper</a>
    • <a href="https://github.com/liuchen11/AdversaryLossLandscape">code</a>
    • <a href="#" onclick="showBibTex(this); return false">bibtex</a>
    <code class="bibtex">@inproceedings{liu2020loss,
title     = {On the Loss Landscape of Adversarial Training: Identifying Challenges and How to Overcome Them},
author    = {Liu, Chen and Salzmann, Mathieu and Lin, Tao and Tomioka, Ryota and S{\"u}sstrunk, Sabine},
booktitle = {Advances in Neural Information Processing Systems},
year      = {2020}
}</code>         
  </li>

  <li>
    <b>Masking as an Efficient Alternative to Finetuning for Pretrained Language Models.</b><br>
    Mengjie Zhao*, <b>Tao Lin*</b>, Fei Mi, Martin Jaggi, Hinrich Schütze.<br>
    EMNLP 2020
    • <a href="https://arxiv.org/abs/2004.12406">long paper</a> 
    • <a href="https://github.com/ptlmasking/maskbert">code</a> 
    • <a href="#" onclick="showBibTex(this); return false">bibtex</a>
    <code class="bibtex">@inproceedings{zhao2020masking,
title     = {Masking as an Efficient Alternative to Finetuning for Pretrained Language Models},
author    = {Zhao, Mengjie and Lin, Tao and Jaggi, Martin and Sch{\"u}tze, Hinrich},
booktitle = {Empirical Methods in Natural Language Processing},
year      = {2020}
}</code>
  </li>

  <li>
    <b>Extrapolation for Large-batch Training in Deep Learning.</b><br>
    <b>Tao Lin*</b>, Lingjing Kong*, Sebastian U. Stich, Martin Jaggi.<br>
    ICML 2020
    • <a href="https://arxiv.org/abs/2006.05720">paper</a>
    • <a href="https://github.com/weilai0980/IMV-LSTM">code</a>
    • <a href="#" onclick="showBibTex(this); return false">bibtex</a>
    <code class="bibtex">@inproceedings{lin2020extrapolation,
title         = {Extrapolation for Large-batch Training in Deep Learning},
author        = {Lin, Tao and Kong, Lingjing and Stich, Sebastian and Jaggi, Martin},
booktitle     = {International Conference on Machine Learning},
pages         = {6094--6104},
year          = {2020},
organization  = {PMLR}
}</code>
  </li>

  <li>
    <b>Dynamic Model Pruning with Feedback.</b><br>
    <b>Tao Lin</b>, Sebastian U. Stich, Luis Barba, Daniil Dmitriev, Martin Jaggi.<br>
    ICLR 2020
    • <a href="https://openreview.net/forum?id=SJem8lSFwB">paper</a>
    • <a href="https://drive.google.com/file/d/1QpFVEpYcj4tAZ1r1o5Htoc3fWEINBApj/view?usp=sharing">code</a>
    • <a href="#" onclick="showBibTex(this); return false">bibtex</a>
    <code class="bibtex">@inproceedings{lin2020dynamic,
title     = {Dynamic Model Pruning with Feedback},
author    = {Lin, Tao and Stich, Sebastian U and Barba, Luis and Dmitriev, Daniil and Jaggi, Martin},
booktitle = {International Conference on Learning Representations},
year      = {2020},
url       = {https://openreview.net/forum?id=SJem8lSFwB}
}</code>      
  </li>

  <li>
    <b>Decentralized Deep Learning with Arbitrary Communication Compression.</b><br>
    Anastasia Koloskova*, <b>Tao Lin*</b>, Sebastian U. Stich, Martin Jaggi.<br>
    ICLR 2020
    • <a href="https://openreview.net/forum?id=SkgGCkrKvH">paper</a>
    • <a href="https://github.com/epfml/ChocoSGD">code</a>
    • <a href="#" onclick="showBibTex(this); return false">bibtex</a>
    <code class="bibtex">@inproceedings{koloskova2020decentralized,
title     = {Decentralized Deep Learning with Arbitrary Communication Compression},
author    = {Koloskova, Anastasia and Lin, Tao and Stich, Sebastian U and Jaggi, Martin},
booktitle = {International Conference on Learning Representations},
year      = {2020},
url       = {https://openreview.net/forum?id=SkgGCkrKvH}
}</code> 
  </li>

  <li>
    <b>Don't Use Large Mini-Batches, Use Local SGD.</b><br>
    <b>Tao Lin</b>, Sebastian U. Stich, Kumar Kshitij Patel, Martin Jaggi.<br>
    ICLR 2020
    • <a href="https://openreview.net/forum?id=B1eyO1BFPr">paper</a>
    • <a href="https://github.com/epfml/LocalSGD-Code">code</a>
    • <a href="#" onclick="showBibTex(this); return false">bibtex</a>
    <code class="bibtex">@inproceedings{lin2020dont,
title     = {Don't Use Large Mini-batches, Use Local SGD},
author    = {Lin, Tao and Stich, Sebastian U and Patel, Kumar Kshitij and Jaggi, Martin},
booktitle = {International Conference on Learning Representations},
year      = {2020},
url       = {https://openreview.net/forum?id=B1eyO1BFPr}
}</code>            
  </li>

  <li>
    <b>Exploring Interpretable LSTM Neural Networks over Multi-Variable Data.</b><br>
    Tian Guo, <b>Tao Lin</b>, Nino Antulov-Fantulin.<br>
    ICML 2019,
    abridged in <a href="https://openreview.net/forum?id=S1nzIYJvz">ICLR 2018 (workshop track)</a>
    • <a href="https://arxiv.org/abs/1905.12034">paper</a>
    • <a href="#" onclick="showBibTex(this); return false">bibtex</a>
    <code class="bibtex">@inproceedings{guo2019exploring,
title         = {Exploring interpretable LSTM neural networks over multi-variable data},
author        = {Guo, Tian and Lin, Tao and Antulov-Fantulin, Nino},
booktitle     = {International Conference on Machine Learning},
pages         = {2494--2504},
year          = {2019},
organization  = {PMLR}
}</code>   
  </li>

  <li>
    <b>Training DNNs with Hybrid Block Floating Point.</b><br>
    Mario Drumond, <b>Tao Lin</b>, Martin Jaggi, Babak Falsafi.<br>
    NeurIPS 2018
    • <a href="https://arxiv.org/abs/1804.01526">paper</a>
    • <a href="https://github.com/parsa-epfl/HBFPEmulator">code</a>
    • <a href="#" onclick="showBibTex(this); return false">bibtex</a>
    <code class="bibtex">@inproceedings{drumond2018training,
title     = {Training DNNs with hybrid block floating point},
author    = {Drumond, Mario and Lin, Tao and Jaggi, Martin and Falsafi, Babak},
booktitle = {Advances in Neural Information Processing Systems},
year      = {2018}
}</code>
  </li>

  <li>
    <b>Hybrid Neural Networks for Learning the Trend in Time Series.</b><br>
    <b>Tao Lin*</b>, Tian Guo*, Karl Aberer.<br>
    IJCAI 2017
    • <a href="https://infoscience.epfl.ch/record/262447?ln=en">paper</a>
    • <a href="#" onclick="showBibTex(this); return false">bibtex</a>
    <code class="bibtex">@inproceedings{lin2017hybrid,
title     = {Hybrid neural networks for learning the trend in time series},
author    = {Lin, Tao and Guo, Tian and Aberer, Karl},
booktitle = {Proceedings of the twenty-sixth international joint conference on artificial intelligence},
number    = {CONF},
pages     = {2273--2279},
year      = {2017}
}</code>
  </li>
</ol>
